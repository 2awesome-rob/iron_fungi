{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceType":"competition","sourceId":84896,"databundleVersionId":10305135},{"sourceType":"datasetVersion","sourceId":9178166,"datasetId":5547076,"databundleVersionId":9360233}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<div style= \"color:SkyBlue; font-size:16px;padding:10px;\">\n    \n**Regression:**\n\n<span style=\"color:PaleGoldenRod; text-transform: uppercase;\">Predict</span> the <span style=\"color:PaleGoldenRod; text-transform: uppercase;\">Insurance Premium</span> from available demographic information.</p>\n**Scoring Criteria:**\nSubmissions are evaluated using <span style=\"color:PaleGoldenRod; text-transform: uppercase;\">Root Mean Squared Logarithmic Error</span>. (RMSLE).\n</div>","metadata":{}},{"cell_type":"markdown","source":"---\n# üíæ Initialize and Load Data","metadata":{}},{"cell_type":"code","source":"# Import libraries\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# Update libraries\n!pip install --upgrade scikit-learn\n!pip install --upgrade plotly  ## 5.24.1 -> 6.3.1\n!pip install --upgrade seaborn  ##  0.12.2 ->  0.12.3\n\n# data manipulation\nimport numpy as np\nimport pandas as pd\n\n# import common libraries and toolkits\nfrom multiprocessing import Pool, cpu_count\n#import sys\n#import os\n\n# machine learning libraries\nimport sklearn as skl\nimport lightgbm as lgb\nimport xgboost as xgb\nimport catboost as catb\n#import umap\n\n# visualization libraries\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n#import plotly as go\n\n# time management\n#import optuna\nfrom time import time\nfrom tqdm import tqdm\n\n# other useful libraries\n#import math \n#from scipy import stats\n#import itertools\n#import random\n\n#import pkg_resources\n#print(\"hdbscan:\", pkg_resources.get_distribution(\"hdbscan\").version)\n#print(\"sklearn:\", skl.__version__)\n#print(\"plotly:\", go.__version__)\n\n\n# reuse my kaggle tabular data functions\nimport urllib.request\n\nurl = \"https://raw.githubusercontent.com/2awesome-rob/iron_fungi/main/my_kaggle_functions.py\"\nurllib.request.urlretrieve(url, \"my_kaggle_functions.py\")\nimport my_kaggle_functions as mkf","metadata":{"trusted":true,"_kg_hide-input":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Specify PATH\nPATH = \"/kaggle/input/playground-series-s4e12/\"\nprint(f\"Home path is: {PATH}\")\n\n#Set globals and load data\nDEVICE, CORES  = mkf.set_globals(verbose = True)\nXY, features, targets, target = mkf.load_tabular_data(PATH)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---\n# üß≠ Exploratory Data Analysis\n## üîé Target","metadata":{}},{"cell_type":"code","source":"# show target stats and plots\nmkf.summarize_data(XY, target)\nmkf.plot_target_eda(XY, target, title = f'{target} distribution')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### üëÄ target observations and notes\n\nTarget: Premium Amount (float). Cost of premium in notional dollars. </p>\n\nTarget distribution has a strong left skew (median $865, mean $1103) with a minimum value of 2 (near 0) and outliers at high values","metadata":{}},{"cell_type":"code","source":"# add labels for plotting, \n#if target is numeric, specify categorical cuts.\nXY, targets = mkf.get_target_labels(XY, target, targets, cuts=8)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---\n## üîç Features","metadata":{}},{"cell_type":"code","source":"mkf.summarize_data(XY, features)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#mkf.plot_features_eda(XY, features[:14], target, 'label', \n#                      high_label=\"pricey\", low_label=\"cheap\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### üëÄ Feature Observations and Notes\n**The target signal is very weak in any given feature**\n\n19 predictive features. \n\n- 5 numeric / magnitude / count\n    - annual_income, number_of_dependents, health_score, previous_claims, credit_score\n- 3 numeric / timedelta\n    - age, vehicle_age, insurance_duration\n- 1 object/ datetime\n    - policy_start_date\n- 4 object / categorical string \n    - marital_status, occupation, location, property_type\n- 4 object / ordinal string \n    - education_level, policy_type, customer_feedback, exercise_frequency\n- 2 object / bool string\n    - gender, smoking_status \n\n---\n## üî∞ Out of the Box Performance","metadata":{}},{"cell_type":"code","source":"mkf.plot_feature_corr(XY, features, target)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"training_features = [f for f in features if \n                     XY[f].dtype!='object']\n\nX_train, y_train, X_val, y_val, X_test, y_test = mkf.split_training_data(\n    XY, training_features, target, validation_size = 0.2, drop_na=True\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"### plot mutual information - may require cleaning prior to evaluation\nmi_scores = mkf.get_feature_mutual_info(X_train, y_train)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# check feature_importance\nmodel = lgb.LGBMRegressor(verbose=-1, n_jobs=CORES)\n\nfeature_importance = mkf.get_feature_importance(\n    X_train, X_val, y_train, y_val, task=\"regression\"\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"single_feature_model, _ = mkf.train_and_score_model(\n    X_train[[feature_importance.index[0]]], X_val[[feature_importance.index[0]]], y_train, y_val, \n    model, task=\"regression_rmsle\"\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"oob_model, _ = mkf.train_and_score_model(\n    X_train, X_val, y_train, y_val, \n    model, task=\"regression_rmsle\"\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### üëÄ Initial Model Observations and Notes\n- As expected based on above EDA, the feature information scores are **very** low!\n- Single Feature Model is NOT predictive\n- OOB Model is also NOT predictive\n- Pulling signal from noise will be challenging!!\n\n---\n# üìè Target Engineering","metadata":{}},{"cell_type":"code","source":"mkf.plot_feature_transforms(XY, target)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"XY, targets, TargetTransformer = mkf.get_target_transformer(\n    XY, target, targets, name='pwr', TargetTransformer=skl.preprocessing.PowerTransformer()\n)\nttarget=targets[-1]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---\n# üìê Feature Engineering\n## üßπ Clean","metadata":{}},{"cell_type":"code","source":"XY = mkf.check_duplicates(XY, features, ttarget, drop=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# missing values\nmissing_data_features = mkf.plot_null_data(XY, features, verbose=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#correct datatype\nXY['policy_start_date'] = pd.to_datetime(XY['policy_start_date'])\n\n#binary map\nXY['gender'].replace({'Female': False, 'Male': True}, inplace=True)\nXY['smoking_status'].replace({'Yes': True, 'No': False}, inplace=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## cleans categoricals and imputes new 'unk' category for missing data\ntraining_features = [f for f in features if XY[f].dtype=='object']\nXY = mkf.clean_categoricals(XY, training_features, string_length=3, fillna=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#imputer strategies\n#fill NaN as noise \nXY['number_of_dependents'].fillna(-1, inplace=True) \nXY['previous_claims'].fillna(-1, inplace=True) \n\n#tag incomplete data rows before filling\nXY['missing_credit'] = XY['credit_score'].isna()\nXY['missing_health'] = XY['health_score'].isna()\n\n#impute to mean or median\nXY['vehicle_age'].fillna(10, inplace=True) \nXY['insurance_duration'].fillna(5, inplace=True) \n#XY['annual_income'] = skl.impute.SimpleImputer(strategy='median').fit_transform(XY['annual_income'].values.reshape(-1,1))\n\ntraining_features = ['age', 'health_score', 'credit_score']\nXY = mkf.impute_using(XY, 'insurance_duration', ['annual_income'])\nXY = mkf.impute_using(XY, 'annual_income', training_features)\n\n#use KNN to impute - this will be slow on large data sets\n#XY[training_features] = skl.impute.KNNImputer(n_neighbors=3).fit_transform(XY[training_features])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# missing values\nmissing_data_features = mkf.plot_null_data(XY, features, verbose=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"training_features = [f for f in features if \n                     (XY[f].dtype=='object' or XY[f].dtype=='category')]\n\nmkf.check_categoricals(XY, training_features, pct_diff=0.5)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#XY = mkf.denoise_categoricals(XY, training_features, target=ttarget, threshold=0.1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### üëÄ Initial Model Observations and Notes\n- occupation and previous_claims missing 30% of data!!\n- number_of_dependents and credit_score missing 10% of data!!\n- Seven other features also missing data\n- Categorical data \"filled\" by creating new category \"unk\"\n- ---\n## üìÖ Datetime Feature Extraction","metadata":{}},{"cell_type":"code","source":"#transform date time to training features\nXY = mkf.get_cycles_from_datetime(XY, 'policy_start_date', drop=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## üî† Categorical Feature Extraction","metadata":{}},{"cell_type":"code","source":"#Converst categoricals to numeric training info\ntraining_features = [f for f in XY.columns if f not in targets and \n                     XY[f].dtype=='category']\nfor f in training_features[:3]:\n    print(f\"{f}: {list(XY[f].unique())}\")\n\n# ordinal features to integers\nXY['education_level'].replace({'hig': 0, 'bac': 1, 'mas':2, 'phd':3}, inplace=True)\nXY['customer_feedback'].replace({'unk': -1, 'poo': 1, 'ave':2, 'goo':3}, inplace=True)\nXY['exercise_frequency'].replace({'dai': 0, 'wee': 1, 'mon':2, 'rar':3}, inplace=True)\n\n#consider using ordinal encoding if appropriate\nXY['policy_type_enc'] = skl.preprocessing.OrdinalEncoder(dtype=np.int8).fit_transform(XY['policy_type'].values.reshape(-1,1))\nXY['policy_type_enc'] = XY['policy_type_enc'].astype('category')\n\n#one hot encode non-ordinal categoricals\ntraining_features = ['marital_status', 'occupation', 'location', 'property_type', 'policy_type']\nXY = pd.get_dummies(XY,columns=training_features)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## üßÆ Expert Features","metadata":{}},{"cell_type":"code","source":"training_features = [f for f in XY.columns if f not in targets and\n                     (XY[f].dtype=='float' or XY[f].dtype=='int') and\n                    '_sin' not in f and '_cos' not in f]\n\nmkf.print_pca_loadings(XY, training_features)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def get_domain_expert_features(df):\n    #PCA 10 health to wealth ratio\n    df['pc10'] = (df['annual_income'] * df['credit_score']) / df['health_score'] * (2+df['previous_claims']) \n    return df\n    \nXY = get_domain_expert_features(XY)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# add simple feature interactions\ntraining_features = [f for f in XY.columns if f not in targets and\n                     f in features and\n                     (XY[f].dtype=='float' or XY[f].dtype=='int')]\n\nXY = mkf.get_feature_interactions(XY, training_features)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## ‚öñÔ∏è Scale/Transform Features","metadata":{}},{"cell_type":"code","source":"training_features = [f for f in XY.columns if f not in targets and\n                     (XY[f].dtype=='float' or XY[f].dtype=='int') and\n                     '_sin' not in f and\n                     '_cos' not in f and\n                     '*' not in f]\n\nfor feat in training_features[-5:]:\n    mkf.plot_feature_transforms(XY, feat)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"mkf.check_all_features_scaled(XY, targets)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#scale / transform numeric features\n# standad transform features\ntraining_features = ['health_score', 'credit_score']\nXY = mkf.get_transformed_features(\n    XY, training_features, skl.preprocessing.StandardScaler()\n)\n\n# power transform features\ntraining_features = ['annual_income', 'pc10']\nXY = mkf.get_transformed_features(\n    XY, training_features, skl.preprocessing.PowerTransformer()\n)\n\n# minmax transform features\ntraining_features = ['age', 'number_of_dependents', 'previous_claims', 'vehicle_age', 'insurance_duration',\n                    'policy_start_date_dummy', 'policy_start_date_doy']\nXY = mkf.get_transformed_features(\n    XY, training_features, skl.preprocessing.MinMaxScaler()\n)\n\nmkf.check_all_features_scaled(XY, targets)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---\n## ‚ûñ Dimension Reduction\n#### Embeddings","metadata":{}},{"cell_type":"code","source":"training_features = [f for f in XY.columns if f in features and\n                     (XY[f].dtype=='float' or XY[f].dtype=='int')]\n\nXY = mkf.get_embeddings(XY, training_features, \n    skl.decomposition.PCA(n_components=4), \"pca_orig_\",\n    target=target, verbose=True\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"training_features = [f for f in XY.columns if f not in targets and\n                     XY[f].dtype!='bool']\n\nXY = mkf.get_embeddings(XY, training_features, \n    skl.decomposition.PCA(n_components=12), \"pca_all_\",\n    target=target, verbose=True\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# rbf features were low info/low importance\n#XY = mkf.get_embeddings(XY, training_features, \n#    skl.kernel_approximation.RBFSampler(n_components=16), \"rbf_\",\n#    verbose=False\n#)\n\n#umap embedding can be slow\n#XY = mkf.get_embeddings(XY, training_features, \n#    umap.UMAP(n_components=16), \"umap_all_\", sample_size=0.1,\n#    target=target, verbose=True\n#)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Clustering","metadata":{}},{"cell_type":"code","source":"training_features = [f for f in XY.columns if f not in targets and\n                     \"pca_\" in f]\n\nXY = mkf.get_clusters(XY, training_features,\n    skl.cluster.KMeans(init=\"k-means++\", n_clusters=6, random_state=69),  \"k_means_pca\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"training_features = [f for f in XY.columns if f not in targets]\n\nXY = mkf.get_clusters(XY, training_features,\n    skl.cluster.KMeans(init=\"k-means++\", n_clusters=12, random_state=69),  \"k_means_all\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#DBSCAN memory usage can be excessive \n#XY = mkf.get_clusters(XY, training_features,\n#    skl.cluster.DBSCAN(eps=2, min_samples=333, metric='euclidean', leaf_size=30, n_jobs=CORES), \"dbscan_pca\", \n#    target=ttarget)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---\n## üìã Evaluate Performance","metadata":{}},{"cell_type":"code","source":"training_features = [f for f in XY.columns if f not in targets and\n                     XY[f].dtype!='object']\n\nX_train, y_train, X_val,  y_val, X_test, y_test = mkf.split_training_data(\n    XY, training_features, ttarget, validation_size = 0.2\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#plot feature correlation\nmkf.plot_feature_corr(XY, training_features, ttarget)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"### updated mutual information\nmi_scores = mkf.get_feature_mutual_info(X_train, y_train)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"### updated feature information\nfeature_importance = mkf.get_feature_importance(\n    X_train, X_val, y_train, y_val, task=\"regression\"\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"updated_model, _ = mkf.train_and_score_model(\n    X_train, X_val, y_train, y_val, \n    model, task=\"regression_rmsle\", \n    TargetTransformer = TargetTransformer\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---\n## üÜñ Outliers","metadata":{}},{"cell_type":"code","source":"XY['model_residual'] = XY[ttarget] - updated_model.predict(XY[training_features])\ntargets.append('model_residual')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"XY, _ = mkf.get_outliers(XY, 'model_residual', deviations = 5, remove=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# üèÉ‚Äç‚ôÇÔ∏è Training and Evaluation\n## üëØ‚Äç‚ôÄÔ∏è Model Selection\n\n- base_models -> model classes\n- models -> base models with hyperparameters\n- training_features -> list of training features for each model class","metadata":{}},{"cell_type":"code","source":"important_features = [f for f in feature_importance.index.tolist() if \n                      (feature_importance[f] > 10 or\n                       mi_scores[f] > 0)]\n\nprint(f\"Not using {[f for f in feature_importance.index.tolist() if f not in important_features]}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"base_models = {\n    'linear' : skl.linear_model.LinearRegression,\n    'lgb' : lgb.LGBMRegressor,\n    'lgb2' : lgb.LGBMRegressor,\n    'catb' : catb.CatBoostRegressor,\n    'hgb' : skl.ensemble.HistGradientBoostingRegressor,\n    'xgb' : xgb.XGBClassifier\n}\n\nparams = {\n    'linear' : {}\n}\n\nmodels, training_features = mkf.get_ready_models(XY, important_features, ttarget, \n    base_models, task='regression', direction='minimize', hyper_params=params,\n    n_features=0, n_trials=3, CORES=CORES, DEVICE=DEVICE, verbose=False,\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## üèãÔ∏è‚Äç‚ôÇÔ∏è Model Training","metadata":{}},{"cell_type":"code","source":"trained_models, stacking_model = mkf.cv_train_models(XY, training_features, ttarget,\n    models, task='regression_rmsle', TargetTransformer=TargetTransformer, \n    folds=5\n    )","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---\n# üîÆ Predict & Submit","metadata":{}},{"cell_type":"code","source":"predictions = mkf.submit_cv_predict(X_test, y_test, training_features, target, \n                      trained_models, task='regression_rmsle',\n                      meta_model=stacking_model,\n                      TargetTransformer=TargetTransformer,\n                      path=PATH, verbose=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}