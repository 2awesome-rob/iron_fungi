{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style= \"color:SkyBlue; font-size:16px;padding:10px;\">\n",
    "    \n",
    "**Regression:**\n",
    "\n",
    "<span style=\"color:PaleGoldenRod; text-transform: uppercase;\">Predict</span> the <span style=\"color:PaleGoldenRod; text-transform: uppercase;\">Insurance Premium</span> from available demographic information.</p>\n",
    "**Scoring Criteria:**\n",
    "Submissions are evaluated using <span style=\"color:PaleGoldenRod; text-transform: uppercase;\">Root Mean Squared Logarithmic Error</span>. (RMSLE).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# üíæ Initialize and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Update libraries\n",
    "!pip install --upgrade scikit-learn\n",
    "!pip install --upgrade plotly  ## 5.24.1 -> 6.3.1\n",
    "!pip install --upgrade seaborn  ##  0.12.2 ->  0.12.3\n",
    "\n",
    "# data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# import common libraries and toolkits\n",
    "from multiprocessing import Pool, cpu_count\n",
    "#import sys\n",
    "#import os\n",
    "\n",
    "# machine learning libraries\n",
    "import sklearn as skl\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import catboost as catb\n",
    "#import umap\n",
    "\n",
    "# visualization libraries\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#import plotly as go\n",
    "\n",
    "# time management\n",
    "#import optuna\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# other useful libraries\n",
    "#import math \n",
    "#from scipy import stats\n",
    "#import itertools\n",
    "#import random\n",
    "\n",
    "#import pkg_resources\n",
    "#print(\"hdbscan:\", pkg_resources.get_distribution(\"hdbscan\").version)\n",
    "#print(\"sklearn:\", skl.__version__)\n",
    "#print(\"plotly:\", go.__version__)\n",
    "\n",
    "\n",
    "# reuse my kaggle tabular data functions\n",
    "import urllib.request\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/2awesome-rob/iron_fungi/main/my_kaggle_functions.py\"\n",
    "urllib.request.urlretrieve(url, \"my_kaggle_functions.py\")\n",
    "import my_kaggle_functions as mkf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Specify PATH\n",
    "PATH = \"/kaggle/input/playground-series-s4e12/\"\n",
    "print(f\"Home path is: {PATH}\")\n",
    "\n",
    "#Set globals and load data\n",
    "DEVICE, CORES  = mkf.set_globals(verbose = True)\n",
    "XY, features, targets, target = mkf.load_tabular_data(PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# üß≠ Exploratory Data Analysis\n",
    "## üîé Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# show target stats and plots\n",
    "mkf.summarize_data(XY, target)\n",
    "mkf.plot_target_eda(XY, target, title = f'{target} distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üëÄ target observations and notes\n",
    "\n",
    "Target: Premium Amount (float). Cost of premium in notional dollars. </p>\n",
    "\n",
    "Target distribution has a strong left skew (median $865, mean $1103) with a minimum value of 2 (near 0) and outliers at high values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# add labels for plotting, \n",
    "#if target is numeric, specify categorical cuts.\n",
    "XY, targets = mkf.get_target_labels(XY, target, targets, cuts=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üîç Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "mkf.summarize_data(XY, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#mkf.plot_features_eda(XY, features[:14], target, 'label', \n",
    "#                      high_label=\"pricey\", low_label=\"cheap\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üëÄ Feature Observations and Notes\n",
    "**The target signal is very weak in any given feature**\n",
    "\n",
    "19 predictive features. \n",
    "\n",
    "- 5 numeric / magnitude / count\n",
    "    - annual_income, number_of_dependents, health_score, previous_claims, credit_score\n",
    "- 3 numeric / timedelta\n",
    "    - age, vehicle_age, insurance_duration\n",
    "- 1 object/ datetime\n",
    "    - policy_start_date\n",
    "- 4 object / categorical string \n",
    "    - marital_status, occupation, location, property_type\n",
    "- 4 object / ordinal string \n",
    "    - education_level, policy_type, customer_feedback, exercise_frequency\n",
    "- 2 object / bool string\n",
    "    - gender, smoking_status \n",
    "\n",
    "---\n",
    "## üî∞ Out of the Box Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "mkf.plot_feature_corr(XY, features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "training_features = [f for f in features if \n",
    "                     XY[f].dtype!='object']\n",
    "\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = mkf.split_training_data(\n",
    "    XY, training_features, target, validation_size = 0.2, drop_na=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### plot mutual information - may require cleaning prior to evaluation\n",
    "mi_scores = mkf.get_feature_mutual_info(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# check feature_importance\n",
    "model = lgb.LGBMRegressor(verbose=-1, n_jobs=CORES)\n",
    "\n",
    "feature_importance = mkf.get_feature_importance(\n",
    "    X_train, X_val, y_train, y_val, task=\"regression\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "single_feature_model, _ = mkf.train_and_score_model(\n",
    "    X_train[[feature_importance.index[0]]], X_val[[feature_importance.index[0]]], y_train, y_val, \n",
    "    model, task=\"regression_rmsle\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "oob_model, _ = mkf.train_and_score_model(\n",
    "    X_train, X_val, y_train, y_val, \n",
    "    model, task=\"regression_rmsle\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üëÄ Initial Model Observations and Notes\n",
    "- As expected based on above EDA, the feature information scores are **very** low!\n",
    "- Single Feature Model is NOT predictive\n",
    "- OOB Model is also NOT predictive\n",
    "- Pulling signal from noise will be challenging!!\n",
    "\n",
    "---\n",
    "# üìè Target Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "mkf.plot_feature_transforms(XY, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "XY, targets, TargetTransformer = mkf.get_target_transformer(\n",
    "    XY, target, targets, name='pwr', TargetTransformer=skl.preprocessing.PowerTransformer()\n",
    ")\n",
    "ttarget=targets[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# üìê Feature Engineering\n",
    "## üßπ Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "XY = mkf.check_duplicates(XY, features, ttarget, drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# missing values\n",
    "missing_data_features = mkf.plot_null_data(XY, features, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#correct datatype\n",
    "XY['policy_start_date'] = pd.to_datetime(XY['policy_start_date'])\n",
    "\n",
    "#binary map\n",
    "XY['gender'].replace({'Female': False, 'Male': True}, inplace=True)\n",
    "XY['smoking_status'].replace({'Yes': True, 'No': False}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "## cleans categoricals and imputes new 'unk' category for missing data\n",
    "training_features = [f for f in features if XY[f].dtype=='object']\n",
    "XY = mkf.clean_categoricals(XY, training_features, string_length=3, fillna=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#imputer strategies\n",
    "#fill NaN as noise \n",
    "XY['number_of_dependents'].fillna(-1, inplace=True) \n",
    "XY['previous_claims'].fillna(-1, inplace=True) \n",
    "\n",
    "#tag incomplete data rows before filling\n",
    "XY['missing_credit'] = XY['credit_score'].isna()\n",
    "XY['missing_health'] = XY['health_score'].isna()\n",
    "\n",
    "#impute to mean or median\n",
    "XY['vehicle_age'].fillna(10, inplace=True) \n",
    "XY['insurance_duration'].fillna(5, inplace=True) \n",
    "#XY['annual_income'] = skl.impute.SimpleImputer(strategy='median').fit_transform(XY['annual_income'].values.reshape(-1,1))\n",
    "\n",
    "training_features = ['age', 'health_score', 'credit_score']\n",
    "XY = mkf.impute_using(XY, 'insurance_duration', ['annual_income'])\n",
    "XY = mkf.impute_using(XY, 'annual_income', training_features)\n",
    "\n",
    "#use KNN to impute - this will be slow on large data sets\n",
    "#XY[training_features] = skl.impute.KNNImputer(n_neighbors=3).fit_transform(XY[training_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# missing values\n",
    "missing_data_features = mkf.plot_null_data(XY, features, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "training_features = [f for f in features if \n",
    "                     (XY[f].dtype=='object' or XY[f].dtype=='category')]\n",
    "\n",
    "mkf.check_categoricals(XY, training_features, pct_diff=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#XY = mkf.denoise_categoricals(XY, training_features, target=ttarget, threshold=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_features = [f for f in features if \n",
    "                     (XY[f].dtype=='float' or XY[f].dtype=='int')]\n",
    "#XY = mkf.tag_outliers_by_neighbors(XY, training_features, n_neighbors=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üëÄ Initial Model Observations and Notes\n",
    "- occupation and previous_claims missing 30% of data!!\n",
    "- number_of_dependents and credit_score missing 10% of data!!\n",
    "- Seven other features also missing data\n",
    "- Categorical data \"filled\" by creating new category \"unk\"\n",
    "- ---\n",
    "## üìÖ Datetime Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#transform date time to training features\n",
    "XY = mkf.get_cycles_from_datetime(XY, 'policy_start_date', drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üî† Categorical Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Converst categoricals to numeric training info\n",
    "training_features = [f for f in XY.columns if f not in targets and \n",
    "                     XY[f].dtype=='category']\n",
    "for f in training_features[:3]:\n",
    "    print(f\"{f}: {list(XY[f].unique())}\")\n",
    "\n",
    "# ordinal features to integers\n",
    "XY['education_level'].replace({'hig': 0, 'bac': 1, 'mas':2, 'phd':3}, inplace=True)\n",
    "XY['customer_feedback'].replace({'unk': -1, 'poo': 1, 'ave':2, 'goo':3}, inplace=True)\n",
    "XY['exercise_frequency'].replace({'dai': 0, 'wee': 1, 'mon':2, 'rar':3}, inplace=True)\n",
    "\n",
    "#consider using ordinal encoding if appropriate\n",
    "XY['policy_type_enc'] = skl.preprocessing.OrdinalEncoder(dtype=np.int8).fit_transform(XY['policy_type'].values.reshape(-1,1))\n",
    "XY['policy_type_enc'] = XY['policy_type_enc'].astype('category')\n",
    "\n",
    "#one hot encode non-ordinal categoricals\n",
    "training_features = ['marital_status', 'occupation', 'location', 'property_type', 'policy_type']\n",
    "XY = pd.get_dummies(XY,columns=training_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üßÆ Expert Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "training_features = [f for f in XY.columns if f not in targets and\n",
    "                     (XY[f].dtype=='float' or XY[f].dtype=='int') and\n",
    "                    '_sin' not in f and '_cos' not in f]\n",
    "\n",
    "mkf.print_pca_loadings(XY, training_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_domain_expert_features(df):\n",
    "    #PCA 10 health to wealth ratio\n",
    "    df['pc10'] = (df['annual_income'] * df['credit_score']) / df['health_score'] * (2+df['previous_claims']) \n",
    "    return df\n",
    "    \n",
    "XY = get_domain_expert_features(XY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# add simple feature interactions\n",
    "training_features = [f for f in XY.columns if f not in targets and\n",
    "                     f in features and\n",
    "                     (XY[f].dtype=='float' or XY[f].dtype=='int')]\n",
    "\n",
    "XY = mkf.get_feature_interactions(XY, training_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "XY = mkf.get_feature_by_grouping_on_cat(XY, ['age', 'credit_score', 'income'], 'education_level')\n",
    "\n",
    "XY = mkf.get_feature_cat_interactions(XY, ['previous_claims', 'exercise_frequency', 'education_level'], 'number_of_dependents')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚öñÔ∏è Scale/Transform Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "training_features = [f for f in XY.columns if f not in targets and\n",
    "                     (XY[f].dtype=='float' or XY[f].dtype=='int') and\n",
    "                     '_sin' not in f and\n",
    "                     '_cos' not in f and\n",
    "                     '*' not in f]\n",
    "\n",
    "for feat in training_features[-5:]:\n",
    "    mkf.plot_feature_transforms(XY, feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "mkf.check_all_features_scaled(XY, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#scale / transform numeric features\n",
    "# standad transform features\n",
    "training_features = ['health_score', 'credit_score']\n",
    "XY = mkf.get_transformed_features(\n",
    "    XY, training_features, skl.preprocessing.StandardScaler()\n",
    ")\n",
    "\n",
    "# power transform features\n",
    "training_features = ['annual_income', 'pc10']\n",
    "XY = mkf.get_transformed_features(\n",
    "    XY, training_features, skl.preprocessing.PowerTransformer()\n",
    ")\n",
    "\n",
    "# minmax transform features\n",
    "training_features = ['age', 'number_of_dependents', 'previous_claims', 'vehicle_age', 'insurance_duration',\n",
    "                    'policy_start_date_dummy', 'policy_start_date_doy']\n",
    "XY = mkf.get_transformed_features(\n",
    "    XY, training_features, skl.preprocessing.MinMaxScaler()\n",
    ")\n",
    "\n",
    "mkf.check_all_features_scaled(XY, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ‚ûñ Dimension Reduction\n",
    "#### Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "training_features = [f for f in XY.columns if f in features and\n",
    "                     (XY[f].dtype=='float' or XY[f].dtype=='int')]\n",
    "\n",
    "XY = mkf.get_embeddings(XY, training_features, \n",
    "    skl.decomposition.PCA(n_components=4), \"pca_orig_\",\n",
    "    target=target, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "training_features = [f for f in XY.columns if f not in targets and\n",
    "                     XY[f].dtype!='bool']\n",
    "\n",
    "XY = mkf.get_embeddings(XY, training_features, \n",
    "    skl.decomposition.PCA(n_components=12), \"pca_all_\",\n",
    "    target=target, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# rbf features were low info/low importance\n",
    "#XY = mkf.get_embeddings(XY, training_features, \n",
    "#    skl.kernel_approximation.RBFSampler(n_components=16), \"rbf_\",\n",
    "#    verbose=False\n",
    "#)\n",
    "\n",
    "#umap embedding can be slow\n",
    "#XY = mkf.get_embeddings(XY, training_features, \n",
    "#    umap.UMAP(n_components=16), \"umap_all_\", sample_size=0.1,\n",
    "#    target=target, verbose=True\n",
    "#)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "training_features = [f for f in XY.columns if f not in targets and\n",
    "                     \"pca_\" in f]\n",
    "\n",
    "XY = mkf.get_clusters(XY, training_features,\n",
    "    skl.cluster.KMeans(init=\"k-means++\", n_clusters=6, random_state=69),  \"k_means_pca\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "training_features = [f for f in XY.columns if f not in targets]\n",
    "\n",
    "XY = mkf.get_clusters(XY, training_features,\n",
    "    skl.cluster.KMeans(init=\"k-means++\", n_clusters=12, random_state=69),  \"k_means_all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#DBSCAN memory usage can be excessive \n",
    "#XY = mkf.get_clusters(XY, training_features,\n",
    "#    skl.cluster.DBSCAN(eps=2, min_samples=333, metric='euclidean', leaf_size=30, n_jobs=CORES), \"dbscan_pca\", \n",
    "#    target=ttarget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üìã Evaluate Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "training_features = [f for f in XY.columns if f not in targets and\n",
    "                     XY[f].dtype!='object']\n",
    "\n",
    "X_train, y_train, X_val,  y_val, X_test, y_test = mkf.split_training_data(\n",
    "    XY, training_features, ttarget, validation_size = 0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#plot feature correlation\n",
    "mkf.plot_feature_corr(XY, training_features, ttarget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### updated mutual information\n",
    "mi_scores = mkf.get_feature_mutual_info(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### updated feature information\n",
    "feature_importance = mkf.get_feature_importance(\n",
    "    X_train, X_val, y_train, y_val, task=\"regression\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "updated_model, _ = mkf.train_and_score_model(\n",
    "    X_train, X_val, y_train, y_val, \n",
    "    model, task=\"regression_rmsle\", \n",
    "    TargetTransformer = TargetTransformer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üÜñ Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "XY['model_residual'] = XY[ttarget] - updated_model.predict(XY[training_features])\n",
    "targets.append('model_residual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "XY, _ = mkf.get_outliers(XY, 'model_residual', deviations = 5, remove=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üèÉ‚Äç‚ôÇÔ∏è Training and Evaluation\n",
    "## üëØ‚Äç‚ôÄÔ∏è Model Selection\n",
    "\n",
    "- base_models -> model classes\n",
    "- models -> base models with hyperparameters\n",
    "- training_features -> list of training features for each model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "important_features = [f for f in feature_importance.index.tolist() if \n",
    "                      (feature_importance[f] > 10 or\n",
    "                       mi_scores[f] > 0)]\n",
    "\n",
    "print(f\"Not using {[f for f in feature_importance.index.tolist() if f not in important_features]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "base_models = {\n",
    "    'linear' : skl.linear_model.LinearRegression,\n",
    "    'lgb' : lgb.LGBMRegressor,\n",
    "    'lgb2' : lgb.LGBMRegressor,\n",
    "    'catb' : catb.CatBoostRegressor,\n",
    "    'hgb' : skl.ensemble.HistGradientBoostingRegressor,\n",
    "    'xgb' : xgb.XGBClassifier\n",
    "}\n",
    "\n",
    "params = {\n",
    "    'linear' : {}\n",
    "}\n",
    "\n",
    "models, training_features = mkf.get_ready_models(XY, important_features, ttarget, \n",
    "    base_models, task='regression', direction='minimize', hyper_params=params,\n",
    "    n_features=0, n_trials=3, CORES=CORES, DEVICE=DEVICE, verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèãÔ∏è‚Äç‚ôÇÔ∏è Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "trained_models, stacking_model = mkf.cv_train_models(XY, training_features, ttarget,\n",
    "    models, task='regression_rmsle', TargetTransformer=TargetTransformer, \n",
    "    folds=5\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# üîÆ Predict & Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "predictions = mkf.submit_cv_predict(X_test, y_test, training_features, target, \n",
    "                      trained_models, task='regression_rmsle',\n",
    "                      meta_model=stacking_model,\n",
    "                      TargetTransformer=TargetTransformer,\n",
    "                      path=PATH, verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 10305135,
     "sourceId": 84896,
     "sourceType": "competition"
    },
    {
     "databundleVersionId": 9360233,
     "datasetId": 5547076,
     "sourceId": 9178166,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
