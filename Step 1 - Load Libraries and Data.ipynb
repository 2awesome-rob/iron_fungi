{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f851a6d3",
   "metadata": {},
   "source": [
    "<span style= \"color:DarkSeaGreen; font-size:16px\"><strong>\n",
    "Challenge: </strong></span>\n",
    "- Predict  <strong><span style=\"color:DarkSeaGreen; text-transform: uppercase;\">target</span></strong> given features\n",
    "- Performance metric is <strong><span style= \"color:DarkSeaGreen\">RMSE</span></strong> between predicted and observed scores.\n",
    "\n",
    "---\n",
    "# ðŸ’¾ Initialize and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27eec521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update libraries - some of these are optional\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import plotly\n",
    "print(plotly.__version__)\n",
    "\n",
    "!pip install --upgrade hdbscan\n",
    "!pip install --upgrade scikit-learn\n",
    "\n",
    "!pip install --upgrade plotly  ## 5.24.1 -> 6.3.1\n",
    "!pip install --upgrade seaborn  ##  0.12.2 ->  0.12.3\n",
    "\n",
    "!pip install --upgrade umap-learn\n",
    "\n",
    "import umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46dd38eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import common libraries and toolkits\n",
    "import sys\n",
    "import os\n",
    "import joblib\n",
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "# data manipulation\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "\n",
    "# machine learning libraries\n",
    "import sklearn as skl\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import catboost as catb\n",
    "\n",
    "# deep learning libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# clustering libraries\n",
    "import hdbscan\n",
    "\n",
    "# hyperparameter optimization\n",
    "import optuna\n",
    "import hyperopt\n",
    "\n",
    "# visualization libraries\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly as go\n",
    "\n",
    "# other useful libraries\n",
    "import math \n",
    "import itertools\n",
    "import random\n",
    "\n",
    "# time management\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "#import pkg_resources\n",
    "#print(\"hdbscan:\", pkg_resources.get_distribution(\"hdbscan\").version)\n",
    "print(\"sklearn:\", skl.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ec6f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set globals\n",
    "\n",
    "# processing settings\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "CORES = min(4, cpu_count())  # Limit cores to avoid memory issues\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "print(f\"Using {CORES} CPU cores when multiprocessing\")\n",
    "\n",
    "# random seed settings for reproducibility\n",
    "SEED = 67\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# visualization settings\n",
    "pd.set_option('display.max_rows', 25)\n",
    "pd.set_option('display.max_columns', 10)\n",
    "pd.set_option('display.max_colwidth', 15)\n",
    "pd.set_option('display.width', 130)\n",
    "pd.set_option('display.precision', 4)\n",
    "\n",
    "# custom seaborn/matplotlib style\n",
    "MY_PALETTE = sns.xkcd_palette(['ocean blue', 'gold', 'dull green', 'dusty rose', 'dark lavender', 'carolina blue', 'sunflower', 'lichen', 'blush pink', 'dusty lavender', 'steel grey'])\n",
    "MY_CMAP = mpl.colors.ListedColormap(MY_PALETTE)\n",
    "sns.set_theme(context = 'paper', style = 'ticks', palette = MY_PALETTE, rc={\"figure.figsize\": (9, 3), \"axes.spines.right\": False, \"axes.spines.top\": False})\n",
    "\n",
    "sns.palplot(MY_PALETTE) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e35c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "### load tabular data\n",
    "def summarize_data(df, features):\n",
    "    \"\"\"prints data summary and descriptive stats\"\"\"\n",
    "    print(\"=\" * 69)\n",
    "    print(df[features].info())\n",
    "    print(\"=\" * 69)\n",
    "    print(df[features].head(5).T) \n",
    "    print(\"=\" * 69)\n",
    "    try:\n",
    "        print(df[features].describe(include=['float', 'int']).T)\n",
    "    except: pass\n",
    "    try:\n",
    "        non_numeric_cols = df[features].select_dtypes(include=['object', 'category', 'bool']).columns\n",
    "        print(df[non_numeric_cols].describe().T)\n",
    "    except: pass\n",
    "\n",
    "\n",
    "def get_target_labels(df, target, targets, cuts = 10):\n",
    "    \"\"\"\n",
    "    Use to visualize continuous target as a categorical\n",
    "    \"\"\"\n",
    "    if df[target].nunique() < 8:\n",
    "        df[\"label\"] = XY[target].max() - XY[target]\n",
    "        targets.append(\"label\")\n",
    "    else:\n",
    "        df[\"qcut_label\"] = cuts  - pd.qcut(df[df.target_mask.eq(True)][target], cuts, labels=False)\n",
    "        df[\"cut_label\"] = cuts  - pd.cut(df[df.target_mask.eq(True)][target], cuts, labels=False)\n",
    "        df[[\"qcut_label\", \"cut_label\"]] = df[[\"qcut_label\", \"cut_label\"]].fillna(-1).astype('int16')\n",
    "        targets.extend([\"qcut_label\", \"cut_label\"])\n",
    "    return df, targets\n",
    "\n",
    "\n",
    "def get_transformed_target(df, target, targets=[], TargetTransformer=None, name=\"std\"):\n",
    "    \"\"\"\n",
    "    scales or transforms targets in df with scikit learn scalers / transformers\n",
    "    returns \n",
    "    1. df with transformed target\n",
    "    2. TargetTransformer to support inverse transformation of predictions\n",
    "    3. updated list of targets\n",
    "    \"\"\"\n",
    "    if TargetTransformer==None: TargetTransformer=skl.preprocessing.StandardScaler()\n",
    "    y = df[df.target_mask.eq(True)][target].values\n",
    "    TargetTransformer.fit(y.reshape(-1,1))\n",
    "    y = df[target].values\n",
    "    df[f\"{target}_{name}\"] = TargetTransformer.transform(y.reshape(-1,1))\n",
    "    targets.append(f\"{target}_{name}\")\n",
    "    return df, TargetTransformer, targets\n",
    "\n",
    "\n",
    "def clean_categoricals(df, features, string_length = 3):\n",
    "    for col in df[features].select_dtypes(include=['object', 'string']).columns:\n",
    "        df[col] = (\n",
    "            df[col]\n",
    "            .astype(str)\n",
    "            .str.strip()\n",
    "            .str.casefold()\n",
    "            .str.replace(\" \", \"_\", regex=False)\n",
    "            .str.replace(\"(\", \"\", regex=False)\n",
    "            .str.replace(\")\", \"\", regex=False)\n",
    "            .str.replace(\"-\", \"_\", regex=False)\n",
    "            .str.replace(\".\", \"_\", regex=False)\n",
    "            .str.replace(\",\", \"_\", regex=False)\n",
    "        )\n",
    "        df[col] = df[col].str[:string_length].astype('category')\n",
    "    return df\n",
    "\n",
    "    \n",
    "def load_tabular_data(path, extra_data = None, verbose = True, csv_sep=\",\"):\n",
    "    \"\"\"\n",
    "    loads tabular data from path into single DataFrame\n",
    "    assumes path contains train.csv, test.csv, sample_submission.csv\n",
    "    if extra_data is provided, it is assumed to be a csv file with additional training data\n",
    "    Returns:\n",
    "    - merged DataFrame for EDA & feature engineering\n",
    "    - list of training features\n",
    "    - list of targets, including column \"target_mask\" for separating test data\n",
    "    - target \n",
    "    \"\"\"\n",
    "    df_train = pd.read_csv(f\"{path}/train.csv\", sep=csv_sep)\n",
    "    df_test = pd.read_csv(f\"{path}/test.csv\", sep=csv_sep)\n",
    "    df_submission = pd.read_csv(f\"{path}/sample_submission.csv\", sep=csv_sep)\n",
    "    \n",
    "    targets = list(df_submission.columns)\n",
    "    features = list(df_test.columns)\n",
    "    id_feature = [feature for feature in features if feature in targets]\n",
    "    assert len(id_feature) == 1, \"Expected exactly one ID column\"\n",
    "    targets = [feature for feature in targets if feature not in id_feature]\n",
    "    features = [feature for feature in features if feature not in id_feature]\n",
    "   \n",
    "    df_test = df_test.merge(df_submission, how = 'left', on = id_feature)\n",
    "    df = pd.concat([df_train.assign(target_mask = True), df_test.assign(target_mask = False)], ignore_index=True)\n",
    "    \n",
    "    if extra_data != None:\n",
    "        df_extra_training = pd.read_csv(f\"{extra_data}\", sep=csv_sep)\n",
    "        missing = set(targets + features + id_feature) - set(df_extra_training.columns)\n",
    "        assert not missing, f\"Extra Data missing columns: {missing}\"\n",
    "        df_extra_training[id_feature[0]] = range(len(df), len(df) + len(df_extra_training))\n",
    "        df = pd.concat([df, df_extra_training.assign(target_mask = True)])\n",
    "    \n",
    "    df.set_index(id_feature, inplace = True)  \n",
    "    ### clean feature names\n",
    "    clean_feature_names = {}\n",
    "    for i, col in enumerate(features):\n",
    "        clean_feature_names[col] = col.casefold().strip().replace(\" \",\"_\").replace(\"(\",\"_\").replace(\")\",\"_\").replace(\"-\",\"_\")\n",
    "        features[i] = clean_feature_names[col]\n",
    "    df.rename(columns=clean_feature_names, inplace=True)\n",
    "    if verbose:\n",
    "        print(\"=\" * 69)\n",
    "        print(f\"Loaded {df.target_mask.eq(True).sum()} training samples of {len(features)} predictive features and {len(targets)} target(s) in DataFrame.\")\n",
    "        print(f\"Loaded {df.target_mask.eq(False).sum()} testing samples in DataFrame.\")\n",
    "        print(f\"DataFrame shape: {df.shape}. Ready to explore, engineer, and predict!\")\n",
    "        print(\"=\" * 69)\n",
    "    targets.append('target_mask')\n",
    "\n",
    "    return df, features, targets, targets[0]\n",
    "\n",
    "\n",
    "def split_training_data(df, features, targets, validation_size = None):\n",
    "    \"\"\"\n",
    "    returns X,y (train & test) values as dataframes based on selcted features and targets\n",
    "    if validation_size provided, returns train, validation, and test dataframes using either\n",
    "    percentage (float) or selected rows (pd.Index)\n",
    "    \"\"\"\n",
    "    XY[XY.target_mask.eq(True)]\n",
    "    X = df[df.target_mask.eq(True)][features]\n",
    "    y = df[df.target_mask.eq(True)][targets]\n",
    "\n",
    "    X_test = df[df.target_mask.eq(False)][features]\n",
    "    y_test = df[df.target_mask.eq(False)][targets]\n",
    "    \n",
    "    if type(validation_size) is float:\n",
    "        X_train, X_val, y_train, y_val  = skl.model_selection.train_test_split(X, y, test_size = validation_size, random_state = SEED)\n",
    "        return X_train, y_train, X_val,  y_val, X_test, y_test\n",
    "    elif type(validation_size) is pd.Index: \n",
    "        X_train, y_train = X[~X.index.isin(validation_size)], y[~y.index.isin(validation_size)]\n",
    "        X_val, y_val = X[X.index.isin(validation_size)], y[y.index.isin(validation_size)]\n",
    "        return X_train, y_train, X_val,  y_val, X_test, y_test\n",
    "    elif validation_size == None: return X, y, X_test, y_test\n",
    "    else:\n",
    "        print(\"Slice Type not recognized\")\n",
    "\n",
    "\n",
    "def calculate_score(actual, predicted, metric='rmse'):\n",
    "    \"\"\" calculates score based on metric or task\n",
    "    \"\"\"\n",
    "    if metric == 'rmse' or metric == 'regression':\n",
    "        return skl.metrics.root_mean_squared_error(actual, predicted)\n",
    "    elif metric == 'accuracy' or metric == 'classification':\n",
    "        return skl.metrics.accuracy_score(actual, predicted)\n",
    "    elif metric == 'auc' or metric == 'classification_probability':\n",
    "        return skl.metrics.roc_auc_score(actual, predicted)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported metric\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1af7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"/kaggle/input/playground-series-s6e1/\"\n",
    "print(f\"Home path is: {PATH}\")\n",
    "\n",
    "# Load data into single DataFrame for Feature Engineering \n",
    "XY, features, targets, target = load_tabular_data(PATH)\n",
    "\n",
    "# Add labels to targets to support plotting feature relationships\n",
    "XY, targets = get_target_labels(XY, target, targets)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
