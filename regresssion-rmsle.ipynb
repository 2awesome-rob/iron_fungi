{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceType":"competition","sourceId":91716,"databundleVersionId":11893428}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<div style= \"color:CadetBlue; font-family: 'Monaco', 'Lucida Console', 'Courier New', monospace; font-size:16px;padding:10px;\">\n    \n**Problem Statement:**\n<span style=\"color:#FEEA00; text-transform: uppercase;\">Predict</span> how many <span style=\"color:#FEEA00; text-transform: uppercase;\">calories</span> were burned during a workout.</p>\n**Scoring Criteria:**\nSubmissions are evaluated using Root Mean Squared Logarithmic Error. (RMSLE).\n</div>","metadata":{}},{"cell_type":"markdown","source":"# üíæ Initialize and Load Data\n","metadata":{"execution":{"iopub.status.busy":"2025-05-06T23:51:43.23416Z","iopub.execute_input":"2025-05-06T23:51:43.234878Z","iopub.status.idle":"2025-05-06T23:51:43.242278Z","shell.execute_reply.started":"2025-05-06T23:51:43.234831Z","shell.execute_reply":"2025-05-06T23:51:43.241308Z"}}},{"cell_type":"code","source":"# Import libraries\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# Update libraries\n!pip install --upgrade scikit-learn\n!pip install --upgrade plotly  ## 5.24.1 -> 6.3.1\n!pip install --upgrade seaborn  ##  0.12.2 ->  0.12.3\n\n# data manipulation\nimport numpy as np\nimport pandas as pd\n\n# import common libraries and toolkits\nfrom multiprocessing import Pool, cpu_count\nimport urllib.request\n#import sys\n#import os\n\n# machine learning libraries\nimport sklearn as skl\nimport lightgbm as lgb\nimport xgboost as xgb\nimport catboost as catb\n\n# visualization libraries\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly as go\n\n# time management\nimport optuna\nfrom time import time\nfrom tqdm import tqdm\n\n# other useful libraries\nimport math \nfrom scipy import stats\nimport itertools\nimport random\n\n#import pkg_resources\n#print(\"hdbscan:\", pkg_resources.get_distribution(\"hdbscan\").version)\n#print(\"sklearn:\", skl.__version__)\n#print(\"plotly:\", go.__version__)\n\n\n# reuse my kaggle tabular data functions\nurl = \"https://raw.githubusercontent.com/2awesome-rob/iron_fungi/main/my_kaggle_functions.py\"\nurllib.request.urlretrieve(url, \"my_kaggle_functions.py\")\nimport my_kaggle_functions as mkf","metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# specify path\nPATH = \"/kaggle/input/playground-series-s5e5/\"\nprint(f\"Home path is: {PATH}\")\n\n# load data\nDEVICE, CORES  = mkf.set_globals(verbose = True)\nXY, features, targets, target = mkf.load_tabular_data(PATH)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---\n# üß≠ Exploratory Data Analysis\n## üîé Target","metadata":{}},{"cell_type":"code","source":"# print target summary stats\nmkf.summarize_data(XY, target)\n\n# plot target distribution\nmkf.plot_target_eda(XY, target, title = f'{target} distribution')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### üëÄ target observations and notes\n\nTarget: Calories (float). Predicted calories burned during workout. </p>\n\nTarget distribution has a strong left skew with outliers at higher values","metadata":{}},{"cell_type":"code","source":"# add labels for plotting\nXY, targets = mkf.get_target_labels(XY, target, targets, cuts=8)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---\n## üîç Features\n","metadata":{}},{"cell_type":"code","source":"# show feature stats\nmkf.summarize_data(XY, features)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"mkf.plot_features_eda(XY, features, target, 'label', \n                      high_label=\"high\", low_label=\"low\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### üëÄ Feature Observations and Notes\n\nSEVEN predictive features.\n \n- 3 numeric / magnitude\n    - temp (deg C): distribution skews high with exponential predictability \n    - height (cm): normal distribution, noise obscures signal  \n    - weight (kg): normal distribution, noise obscures signal  \n- 2 numeric / timedelta\n    - age (years): distribution skews young, noise obscures signal\n    - duration (min): distribution is uniform, quadradic predictability\n\n- 1 numeric / frequency \n    - heartrate (bpm): normally distributed, with near linear predictability\n- 1 object / bool string\n    - sex: distribution is balanced, with males over-represented in high calorie trials\n\n\n---\n## üî∞ Out of the Box Performance","metadata":{}},{"cell_type":"code","source":"training_features = [f for f in features if \n                     XY[f].dtype!='object']\n\nX_train, y_train, X_val,  y_val, X_test, y_test = mkf.split_training_data(\n    XY, training_features, target, validation_size = 0.2\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"### plot mutual information\nmi_scores = mkf.get_feature_mutual_info(X_train, y_train)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# check feature_importance\nmodel = lgb.LGBMRegressor(verbose=-1, n_jobs=CORES)\n\nfeature_importance = mkf.get_feature_importance(\n    X_train, X_val, y_train, y_val, task=\"regression\"\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"single_feature_model, _ = mkf.train_and_score_model(\n    X_train[[mi_scores.index[0]]], X_val[[mi_scores.index[0]]], y_train, y_val, \n    model, task=\"regression_rmsle\"\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"oob_model, _ = mkf.train_and_score_model(\n    X_train, X_val, y_train, y_val, \n    model, task=\"regression_rmsle\"\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### üëÄ Initial Model Observations and Notes\n- Single Feature Model is predictive, with lots of noise (RMSLE = 0.1818)\n- Model is actually very good out of the box (RMSLE = 0.0771)\n- Most |residuals| < 25, but some outliers to > 100\n- Untuned LGBM significantly outperforms GaussianNB\n\n---\n# üìè Target Engineering","metadata":{}},{"cell_type":"code","source":"### Plot target feature transform functions\nmkf.plot_feature_transforms(XY, target)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### üëÄ Target Transform Observations\n- [ ] TODO Compare PowerTransform to QuantileTransform appearance","metadata":{}},{"cell_type":"code","source":"#Encode the target and plot distribution\nXY, targets, TargetTransformer = mkf.get_target_transformer(\n    XY, target, targets, name=\"pwr\",\n    TargetTransformer=skl.preprocessing.PowerTransformer())\n\nttarget=targets[-1]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---\n# üìê Feature Engineering\n## üßπ Clean","metadata":{}},{"cell_type":"code","source":"### Explore missing values\nmkf.plot_null_data(XY, features)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"### Imputer","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"### Remove Duplicates\nXY = mkf.check_duplicates(XY, features, ttarget, drop=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---\n## üßÆ Transform Features","metadata":{}},{"cell_type":"code","source":"### bool string -> numeric boolean\nXY['sex'].replace({'male': 1, 'female': -1}, inplace=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"mkf.print_pca_loadings(XY, features)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#### Generate Expert features before scaling\ndef get_domain_expert_features(df):\n    ### healthy height weight ratio -> PCA 7\n    df['bmi'] = df['weight']/ ((df['height']/100) **2) \n    df['height_weight_ratio'] = df['weight']/df['height']\n    ###https://www.calculator.net/ideal-weight-calculator.html\n    # Male:   48.0 kg + 2.7 kg per inch over 5 feet\n    # Female: 45.5 kg + 2.2 kg per inch over 5 feet\n    df['male'] = df['sex'].replace({1:1, -1:0})\n    df['hanwi'] = df['weight'] - (45.5 + (df['male'] * (48-45.5)) + (2.2 + (df['sex'] * (2.7-2.2)))*(df['height']-152.4)/2.54)\n    # Male:\t  56.2 kg + 1.41 kg per inch over 5 feet\n    # Female: 53.1 kg + 1.36 kg per inch over 5 feet\n    df['miller'] = df['weight'] - (53.1 + (df['male'] * (56.2-53.1)) + (1.36 + (df['sex'] * (1.41-1.36)))*(df['height']-152.4))\n    df.drop('male', inplace=True, axis=1)\n    feats = ['bmi', 'height_weight_ratio', 'hanwi', 'miller']\n    df = mkf.get_transformed_features(df, feats, skl.preprocessing.StandardScaler(), winsorize=[0.001, 0.001])\n    ### temp vs heart rate -> PCA 5\n    df['vital_ratio'] = df['heart_rate'] / df['body_temp']\n    ## delta from reference\n    df['body_temp'] +=  -37\n    df['heart_rate'] +=  -60\n    ### effort \n    df['effort'] = df['heart_rate'] * df['body_temp'] * df['duration']\n    ### effort per size -> PCA 1\n    df['size_effort'] = df['effort'] / (df['weight'] * df['height'])\n    ### total effort -> PCA 2\n    df['max_effort'] = df['effort'] * df['weight'] * df['height']\n    ### workout effort per unit time -> PCA 6\n    df['burn_rate'] = df['body_temp'] * df['heart_rate'] / df['duration'] \n    feats = ['effort', 'size_effort', 'max_effort', 'vital_ratio', 'burn_rate']\n    df = mkf.get_transformed_features(df, feats , skl.preprocessing.PowerTransformer(), winsorize=[0.001, 0.001])\n    XY['temp_2'] = XY['body_temp'] ** 2\n    XY['temp_3'] = XY['body_temp'] ** 3\n    XY['temp_4'] = XY['body_temp'] ** 4\n    feats = ['temp_2', 'temp_3', 'temp_4']\n    df = mkf.get_transformed_features(df, feats , skl.preprocessing.MinMaxScaler())\n    return df\n\nXY = get_domain_expert_features(XY)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"### Plot scalar feature transform functions\ntraining_features = [f for f in features if f != \"sex\"]\n\nfor f in training_features:\n    mkf.plot_feature_transforms(XY, f)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"training_features = ['height', 'weight', 'heart_rate']\nXY = mkf.get_transformed_features(XY, training_features, skl.preprocessing.StandardScaler())\n\ntraining_features = ['body_temp']\nXY = mkf.get_transformed_features(XY, training_features, skl.preprocessing.PowerTransformer())\n\ntraining_features = ['duration']\nXY = mkf.get_transformed_features(XY, training_features, skl.preprocessing.MinMaxScaler())\n\nXY['age'] = np.log1p(XY['age'])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---\n## ‚ûï Add Features","metadata":{}},{"cell_type":"code","source":"training_features = [features]\nXY = mkf.get_feature_interactions(XY, features, winsorize=[0.001, 0.001])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---\n## ‚ûñ Dimension Reduction\n#### Embeddings","metadata":{"execution":{"iopub.status.busy":"2026-02-20T16:56:22.526414Z","iopub.execute_input":"2026-02-20T16:56:22.527426Z","iopub.status.idle":"2026-02-20T16:56:22.533567Z","shell.execute_reply.started":"2026-02-20T16:56:22.527392Z","shell.execute_reply":"2026-02-20T16:56:22.532258Z"}}},{"cell_type":"code","source":"XY = mkf.get_embeddings(XY, features, \n    skl.decomposition.PCA(n_components=5), \"pca_orig_\",\n    target=target, verbose=True\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 'All' training features\ntraining_features = [f for f in XY.columns if f not in targets and\n                    \"pca_\" not in f]\n\n# rbf features were low info/low importance\n#XY = mkf.get_embeddings(XY, training_features, \n#    skl.kernel_approximation.RBFSampler(n_components=16), \"rbf_\",\n#    verbose=False\n#)\n\nXY = mkf.get_embeddings(XY, training_features, \n    skl.decomposition.PCA(n_components=10), \"pca_all_\",\n    target=target, verbose=True\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Clustering","metadata":{}},{"cell_type":"code","source":"training_features = [f for f in XY.columns if f not in targets and\n                     \"pca_\" in f]\n\nXY = mkf.get_clusters(XY, training_features,\n    skl.cluster.KMeans(init=\"k-means++\", n_clusters=5, random_state=69),  \"k_means_pca\",\n    target=ttarget)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#DBSCAN memory usage was excessive \n#XY = mkf.get_clusters(XY, training_features,\n#    skl.cluster.DBSCAN(eps=2, min_samples=333, metric='euclidean', leaf_size=30, n_jobs=CORES), \"dbscan_pca\", \n#    target=ttarget)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"training_features = [f for f in XY.columns if f not in targets and\n                     \"pca_\" not in f and\n                     \"scan_\" not in f and\n                     \"k_means_\" not in f \n                    ]\n\nXY = mkf.get_clusters(XY, training_features,\n    skl.cluster.KMeans(init=\"k-means++\", n_clusters=8, random_state=69),  \"k_means_all\",\n    target=ttarget)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---\n## üü∞ Evaluate Performance","metadata":{}},{"cell_type":"code","source":"training_features = [f for f in XY.columns if f not in targets and\n                     XY[f].dtype!='object']\n\nX_train, y_train, X_val,  y_val, X_test, y_test = mkf.split_training_data(\n    XY, training_features, ttarget, validation_size = 0.2\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"### updated mutual information\nmi_scores = mkf.get_feature_mutual_info(X_train, y_train)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"### updated feature information\nfeature_importance = mkf.get_feature_importance(\n    X_train, X_val, y_train, y_val, task=\"regression\"\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"updated_model, _ = mkf.train_and_score_model(\n    X_train, X_val, y_train, y_val, \n    model, task=\"regression_rmsle\", \n    TargetTransformer = TargetTransformer\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### üëÄ Updated Model Observations and Notes\n- Model shows improvement (RMSLE = 0.0771 -> 0.0632)\n- [ ] TODO: Investigate outliers in residuals \n\n---\n## üÜñ Outliers","metadata":{}},{"cell_type":"code","source":"XY['model_residual'] = XY[ttarget] - updated_model.predict(XY[training_features])\ntargets.append('model_residual')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def get_outliers(df, features, target, out_feature, deviations=4, verbose=False):\n    df_train = df[df.target_mask.eq(True)]\n    m = df_train[out_feature].mean()\n    s = df_train[out_feature].std()\n    pop = df_train.shape[0]\n    print(\"=\" * 69)\n    print(f\"{pop} samples with mean: {m:.4f} std: {s:.4f}\")\n    for i in range(1, deviations+1):\n        df_outlier = df_train[(df_train[out_feature] > i*(m+s)) | (df_train[out_feature] < i*(m-s))]\n        print(f\"  {pop - df_outlier.shape[0]} ({100*(1-df_outlier.shape[0]/pop):.2f}%) samples within {i} standard deviation \")\n    print(\"=\" * 69)\n    print(f\"{df_outlier.shape[0]} outliers identified\")\n    if verbose:\n        print(df_outlier.head().T)\n    return df_outlier\n\noutliers = get_outliers(XY, features, target, 'model_residual', deviations = 5)\n\n#remove outliers\nXY = XY[~XY.index.isin(outliers.index)]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# üèÉ‚Äç‚ôÇÔ∏è Training and Evaluation\n## üëØ‚Äç‚ôÄÔ∏è Model Selection\n\n- base_models -> model classes\n- models -> base models with hyperparameters\n- training_features -> list of training features for each model class","metadata":{}},{"cell_type":"code","source":"important_features = [f for f in feature_importance.index.tolist() if \n                      (feature_importance[f] > 2 or\n                       mi_scores[f] > 0.2)]\n\nprint(f\"Not using {[f for f in feature_importance.index.tolist() if f not in important_features]}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"base_models = {\n#    'lr' : skl.linear_model.LogisticRegression, \n    'lgb' : lgb.LGBMRegressor,\n    'lgb2' : lgb.LGBMRegressor,\n    'xgb' : xgb.XGBRegressor, \n    'xgb2' : xgb.XGBRegressor, \n    'hgb' : skl.ensemble.HistGradientBoostingRegressor,\n}\n\nparams = {\n    'lr' : {'C': 0.6, 'max_iter': 267, 'solver': 'sag'}, \n    'mlp' : {'hidden_layer_sizes' : (64,64), 'random_state' : 69},\n#    'hgb' : {'max_iter': 1000, 'learning_rate': 0.038, 'max_leaf_nodes': 24, 'min_samples_leaf': 24, 'l2_regularization': 0.008, 'early_stopping': True}\n}\n\nmodels, training_features = mkf.get_ready_models(XY, important_features, target, \n    base_models, task='regression', direction='minimize', hyper_params=params,\n    n_features=3, n_trials=22, CORES=CORES, DEVICE=DEVICE, verbose=False,\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## üèãÔ∏è‚Äç‚ôÇÔ∏è Model Training","metadata":{}},{"cell_type":"code","source":"trained_models, stacking_model = mkf.cv_train_models(XY, training_features, target,\n    models, task='regression_rmsle', TargetTransformer=TargetTransformer, \n    folds=11\n    )","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---\n# üîÆ Predict & Submit","metadata":{}},{"cell_type":"code","source":"predictions = mkf.submit_cv_predict(X_test, y_test, training_features, target, \n                      trained_models, task='regression_rmsle',\n                      meta_model=stacking_model,\n                      TargetTransformer=TargetTransformer,\n                      path=PATH, verbose=True)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}