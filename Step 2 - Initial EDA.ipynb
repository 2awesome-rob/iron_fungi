{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f851a6d3",
   "metadata": {},
   "source": [
    "---\n",
    "# ðŸ§­ Exporatory Data Analysis\n",
    "## ðŸŽ¯ Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27eec521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizations\n",
    "\n",
    "def plot_target_eda(df, target, title = f'target distribution'):\n",
    "    \"\"\"\n",
    "    simple target distribution plot for classification or regression\n",
    "    \"\"\"\n",
    "    if pd.api.types.is_float_dtype(df[target]) or (df[target].dtype == int and df[target].nunique() > 20):\n",
    "        sns.histplot(df[target], bins = min(df[target].nunique(), 42), kde = True)\n",
    "    else:\n",
    "        sns.countplot(data=df, x=target)\n",
    "    plt.title(title)\n",
    "    plt.yticks([])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_features_eda(df, features, target, label, sample = 1000,\n",
    "                      high_label = \"Good\", low_label = \"Bad\",\n",
    "                      y_min = None, y_max = None):\n",
    "    \"\"\" \n",
    "    supports feature EDA with continuous or integer targets\n",
    "    may need to adjust y_max and y_min to support limits of continuous target\n",
    "    \"\"\"\n",
    "    ### Histogram for distribution of numeric feature (num plot 0)\n",
    "    def _plot_num_distribution(ax, feature):\n",
    "        sns.histplot(df[feature], ax=ax, bins = 50)\n",
    "        ax.set_title(f'{feature} distribution')\n",
    "        ax.set_yticks([])\n",
    "        ax.set_ylabel(\"Count\")\n",
    "        ax.set_xlabel(\"\")\n",
    "    \n",
    "    ### Countplot for distribution of categorical feature (cat plot 0)\n",
    "    def _plot_cat_distribution(ax, feature, order, color_map):\n",
    "        sns.countplot(data=df, x=feature, order=order, ax=ax,\n",
    "                      palette=[color_map[val] for val in order])\n",
    "        ax.set_title(f'{feature} distribution')\n",
    "        ax.set_yticks([])\n",
    "        ax.set_ylabel(\"Count\")\n",
    "        if len(order) > 8: \n",
    "            x = ax.get_xticks()\n",
    "            ax.set_xticks(x, order, rotation=90)\n",
    "        if len(order) > 20:\n",
    "            x = ax.get_xticks()\n",
    "            labels = [s if i % 5 == 0 else \"\" for i, s in enumerate(order)]\n",
    "            ax.set_xticks(x, labels, rotation=90)\n",
    "        ax.set_xlabel(\"\")\n",
    "\n",
    "    ### scatterplot with trendline for numerical feature relationship to target (num plot 1)\n",
    "    def _plot_num_relationship(ax, feature,  y_min=0, y_max=100):\n",
    "        df_sampled = df.sample(n=min(sample, df.shape[0]), random_state=SEED)\n",
    "        sns.regplot(data=df_sampled, x=feature, y=target, ax=ax,\n",
    "                    scatter_kws={'alpha': 0.5, 's': 12}, line_kws={'color': 'xkcd:dusty rose', 'linestyle': \"--\", 'linewidth': 2})\n",
    "        ax.set_title(f'{target} vs {feature}')\n",
    "        ax.set_ylabel(\"\")\n",
    "        ax.set_ylim(y_min, y_max)\n",
    "        ax.set_xlabel(\"\")\n",
    "\n",
    "    ### psedo-scatterplot with trendline for categorical feature relationship to target (cat plot 1)\n",
    "    def _plot_cat_relationship(ax, feature, order, color_map, y_min=0, y_max=100):\n",
    "        grouped = df.groupby(feature)\n",
    "        sampled_dfs = []\n",
    "        for name, group in grouped:\n",
    "            frac = min(1.0, sample / len(df))\n",
    "            sampled_dfs.append(group.sample(n=max(1, int(frac * len(group))), random_state=SEED))\n",
    "        df_sampled = pd.concat(sampled_dfs)\n",
    "        sns.stripplot(data=df_sampled, x=feature, y=target, order=order, ax=ax, zorder = 1, \n",
    "                          palette=[color_map[val] for val in order], alpha=0.5, jitter=True)\n",
    "        sns.pointplot(data=df, x=feature, y=target, order=order, ax=ax, zorder = 2, \n",
    "                      color=MY_PALETTE[-1], errorbar = None)\n",
    "\n",
    "        if len(df[target].unique()) > 5:\n",
    "            for i, val in enumerate(order):\n",
    "                subset = df[df[feature] == val][target].dropna()\n",
    "                q25, q75 = subset.quantile([0.25, 0.75])\n",
    "                ax.vlines(x=i, ymin=q25, ymax=q75, color=MY_PALETTE[-1], linewidth=2,  zorder = 3)\n",
    "        \n",
    "        ax.set_title(f'{target} vs {feature}')\n",
    "        if len(order) > 8: \n",
    "            x = ax.get_xticks()\n",
    "            ax.set_xticks(x, order, rotation=90)\n",
    "        if len(order) > 20:\n",
    "            x = ax.get_xticks()\n",
    "            labels = [s if i % 5 == 0 else \"\" for i, s in enumerate(order)]\n",
    "            ax.set_xticks(x, labels, rotation=90)\n",
    "        ax.set_ylabel(\"\")\n",
    "        ax.set_ylim(y_min, y_max)\n",
    "        ax.set_xlabel(\"\")\n",
    "\n",
    "    ### boxplot shows outliers and limits by label  (num plot 2)\n",
    "    def _plot_num_boxplot(ax, feature, label = None, top_label=\"\", bottom_label=\"\"):        \n",
    "        if label == None:\n",
    "            sns.boxplot(x = df[feature], ax=ax)\n",
    "            ax.set_title(f'{feature} outliers')\n",
    "        else:\n",
    "            sns.boxplot(x = df[feature], palette=MY_PALETTE , ax=ax, legend = False, gap = .1,\n",
    "                        hue = df[label], hue_order = sorted(df[label].dropna().unique().tolist()))\n",
    "            ax.set_title(f'{feature} by target cut')\n",
    "            ax.set_xlabel(\"\")\n",
    "            ax.text(df[feature].min(), -0.45, top_label, ha='left', va='center', fontsize=8, color = 'black')\n",
    "            ax.text(df[feature].min(), 0.45, bottom_label, ha='left', va='center', fontsize=8, color = 'black')\n",
    "        ax.set_yticks([])\n",
    "\n",
    "    ### donut shows variation in target by category  (cat plot 2)\n",
    "    def _plot_cat_donut(ax, feature, label, order, color_map, inner_label=\"\", outer_label=\"\"):\n",
    "        cats = sorted(df[label].dropna().unique().tolist())\n",
    "        ring_width = 0.7 / len(cats)\n",
    "        for i, cat in enumerate(cats):\n",
    "            value_counts = df[df[label] == cat][feature].value_counts()\n",
    "            sorted_counts = value_counts.reindex(order).dropna()\n",
    "            if len(order) > 20:\n",
    "                labels = [s if i % 5 == 0 else \"\" for i, s in enumerate(sorted_counts.index)]\n",
    "            else: labels = sorted_counts.index\n",
    "            slice_colors = [color_map[val] for val in sorted_counts.index]\n",
    "            radius = 1 - ring_width * i\n",
    "            ax.pie(sorted_counts, radius=radius, colors=slice_colors,\n",
    "                   wedgeprops=dict(width=ring_width, edgecolor='w'),\n",
    "                   labels=labels if i == 0 else None)\n",
    "            ax.set_title(f'{feature} by target cut')\n",
    "            ax.text(0, 0, inner_label, ha='center', va='center', fontsize=8, color = 'xkcd:steel grey')\n",
    "            ax.text(-1.3, -1.3, outer_label, ha='left', va='center', fontsize=8, color = 'xkcd:steel grey')\n",
    "\n",
    "    ### build common cmap for categoricals\n",
    "    def _set_color_map(order, clrs = 6, sats = 5):\n",
    "        if len(order) <= len(MY_PALETTE):\n",
    "            return dict(zip(order, MY_PALETTE[:len(order)]))\n",
    "        elif len(order) <= clrs * sats:\n",
    "            new_palette = []\n",
    "            for j in range(clrs):\n",
    "                for i in range(sats):\n",
    "                    new_palette.append(sns.desaturate(MY_PALETTE[j], 1-.2*i))\n",
    "            return dict(zip(order, new_palette[:len(order)]))\n",
    "        else:\n",
    "            cmap = mpl.colormaps['cividis'].resampled(len(order))\n",
    "            new_palette = [cmap(i / len(order)) for i in range(len(order))]\n",
    "            return dict(zip(order, new_palette))\n",
    "\n",
    "    ### limit number of features plotted/size of plot\n",
    "    f = len(features)\n",
    "    if len(features) > 20:\n",
    "        print(\"Plotting 20 features\")\n",
    "        f = 20\n",
    "        features = features[:20]\n",
    "\n",
    "    ### define limits of relationship plots\n",
    "    if not y_min: y_min = df[target].min()\n",
    "    if not y_max: y_max = df[target].max()\n",
    "    \n",
    "    ### gridspec to build plot layout\n",
    "    fig = plt.figure(figsize=(10, f * 3))\n",
    "    gs = mpl.gridspec.GridSpec(f, 3, figure=fig, hspace=0.4)\n",
    "    \n",
    "    row_anchors = []\n",
    "    for i, feature in enumerate(features):\n",
    "        ### for each feature determine applicable plot selection\n",
    "        is_cat = (df[feature].dtype == \"O\" or df[feature].dtype == bool or df[feature].dtype == \"category\" or\n",
    "                  (np.issubdtype(df[feature].dtype, np.integer) and len(df[feature].dropna().unique()) < 10))\n",
    "        ax0 = fig.add_subplot(gs[i, 0])\n",
    "        row_anchors.append(ax0)\n",
    "        if is_cat:\n",
    "            order = sorted(df[feature].dropna().unique().tolist())\n",
    "            color_map = _set_color_map(order)\n",
    "            _plot_cat_distribution(ax0, feature, order, color_map)\n",
    "            _plot_cat_relationship(fig.add_subplot(gs[i, 1]), feature, order, color_map, y_min=y_min, y_max=y_max)\n",
    "            _plot_cat_donut(fig.add_subplot(gs[i, 2]), feature, label, order, color_map,\n",
    "                           inner_label=low_label, outer_label=high_label)\n",
    "        else:\n",
    "            _plot_num_distribution(ax0, feature)\n",
    "            _plot_num_relationship(fig.add_subplot(gs[i, 1]), feature, y_min=y_min, y_max=y_max)\n",
    "            _plot_num_boxplot(fig.add_subplot(gs[i, 2]), feature, label, \n",
    "                            top_label=high_label, bottom_label=low_label)\n",
    "\n",
    "    ### add tear lines between features\n",
    "    for i in range(f - 1):\n",
    "        bottom_y = row_anchors[i].get_position().y0\n",
    "        top_y = row_anchors[i + 1].get_position().y1\n",
    "        y_pos = (bottom_y + top_y) / 2\n",
    "        line = mpl.lines.Line2D([0.05, 0.95], [y_pos, y_pos], transform=fig.transFigure,\n",
    "                      color='black', linewidth=0.5, linestyle='--')\n",
    "        fig.add_artist(line)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def plot_pairplot(df, features, sample = 250, title = \"\", **kwargs):\n",
    "    \"\"\"\n",
    "    pairplot for feature to feature comparisons\n",
    "    \"\"\"\n",
    "    print(\"=\" * 69)\n",
    "    plot_df = df[features].sample(n = min(sample, df.shape[0]), random_state=SEED)\n",
    "    g = sns.pairplot(plot_df, diag_kind=\"kde\", **kwargs)\n",
    "    g.map_lower(sns.kdeplot, levels=4, color=\"xkcd:slate\")\n",
    "    g.figure.suptitle(title, x = 0.98, ha = 'right', y=1.01)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46dd38eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_data(XY[XY.target_mask.eq(True)], target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ec6f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_target_eda(XY[XY.target_mask.eq(True)], target, title=f'{target} distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e35c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast to integer useful for some target transformations\n",
    "target_int = f'{target}_int'\n",
    "XY[target_int] = XY[target].astype('int')\n",
    "targets.append(target_int)\n",
    "\n",
    "# Scale and transform target\n",
    "XY, TargetTransformer_mms, targets = get_transformed_target(XY, \n",
    "    target, targets,\n",
    "    skl.preprocessing.MinMaxScaler((-1,1)),\n",
    "    \"mms\")\n",
    "target_mms = targets[-1]\n",
    "\n",
    "# Normal quantile cut emphasizes the clustering at extreames\n",
    "XY, TargetTransformer_n, targets = get_transformed_target(XY, target, targets,\n",
    "    skl.preprocessing.QuantileTransformer(\n",
    "        n_quantiles=100,\n",
    "        output_distribution=\"normal\",\n",
    "        subsample=100000),\n",
    "    \"qn\")\n",
    "target_n = targets[-1]\n",
    "\n",
    "# Uniform quantile cut transforms to uniform distribution\n",
    "XY, TargetTransformer_u, targets = get_transformed_target(XY, target, targets,\n",
    "    skl.preprocessing.QuantileTransformer(\n",
    "        n_quantiles=100,\n",
    "        output_distribution=\"uniform\", \n",
    "        subsample=100000),\n",
    "    \"qu\")\n",
    "target_u = targets[-1]\n",
    "\n",
    "# Binary classification targets\n",
    "grade_a = 90\n",
    "grade_f = 38\n",
    "XY[f'{target}_a'] = XY[target_int].apply(lambda e:1 if e>grade_a else 0)\n",
    "XY[f'{target}_f'] = XY[target_int].apply(lambda e:1 if e<grade_f else 0)\n",
    "targets.extend([f'{target}_a', f'{target}_f'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1af7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_target_eda(XY[XY.target_mask.eq(True)],\n",
    "                target_u, title=f'{target_u} distribution')\n",
    "plot_target_eda(XY[XY.target_mask.eq(True)],\n",
    "                target_int, title=f'{target} distribution')\n",
    "\n",
    "plot_target_eda(XY[XY.target_mask.eq(True) & XY.exam_score_a.eq(1)],\n",
    "                target_int, title=f'High Score distribution')\n",
    "\n",
    "plot_target_eda(XY[XY.target_mask.eq(True) & XY.exam_score_f.eq(1)],\n",
    "                target_int, title=f'Low Score distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe9c71f",
   "metadata": {},
   "source": [
    "#### ðŸ‘€ target observations and notesÂ¶\n",
    "- target is continuous over range 0 to 100\n",
    "- target has a very slight right skew, mean score 62\n",
    "- historgram grouping algorithm may generate apparent gaps/drops in data\n",
    "    - algorithm artifact, data appears well shaped away from extreames\n",
    "- n.b. significant peaks at high end(100) and low end (19);\n",
    "    - approximately 2.45% score 100, vs 0.36% score 99\n",
    "    - similarly 1.09% score 19 vs 0.14 score 20\n",
    "---\n",
    "## ðŸ”¬ Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb85d619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show feature stats\n",
    "summarize_data(XY[XY.target_mask.eq(True)], features)\n",
    "\n",
    "summarize_data(XY[XY.target_mask.eq(True) & XY.exam_score_int.eq(100)],\n",
    "                features)\n",
    "summarize_data(XY[XY.target_mask.eq(True) & XY.exam_score_a.eq(1)],\n",
    "                features)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a95f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean boolean and ordinal features\n",
    "XY.feature.replace({'yes': True, 'no': False}, inplace=True)\n",
    "XY.feature.replace({'poor': 1, 'average': 3, 'good': 5}, inplace=True)\n",
    "XY.feature.replace({'low': 1, 'medium': 3, 'high': 5}, inplace=True)\n",
    "\n",
    "# Clean and trim categorical strings\n",
    "XY = clean_categoricals(XY, features, string_length = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0ef0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_features_eda(XY[XY.target_mask.eq(True)],\n",
    "                  features, target, 'cut_label',\n",
    "                  high_label=\"high score\", low_label=\"low\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf13d11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_features_eda(XY[XY.target_mask.eq(True) & XY.exam_score_a.eq(1)],\n",
    "                  features, target, 'cut_label',\n",
    "                  high_label=\"high score\", low_label=\"low\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf42bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### ðŸ‘€ Feature Observations and Notes\n",
    "- 11 predictive features: 4 numeric, 1 boolean, and 6 categorical\n",
    "- No missing data\n",
    "- [x] DONE: clean and simplify categorical string values in support of display and encoding\n",
    "- [x] DONE: map boolean to True/False\n",
    "- [x] DONE: assign ordinal categories numeric mapping\n",
    "\n",
    "<span style= \"color:DarkSeaGreen; font-size:16px\"><strong>\n",
    "Numeric features:</strong></span>\n",
    "- age: near uniform distribution, **no** significant predictive power\n",
    "- study_hours: near uniform with **significant peaks at high/low extreams**, **strong positive** correlation to exam scores\n",
    "- class_attendance: near uniform distribution with **peak at high attendence**, **positive** correlation to exam scores\n",
    "- sleep_hours: near uniform distribution periodic peaks (round numbers?), **weak positive** correlation to exam scores\n",
    "\n",
    "<span style= \"color:DarkSeaGreen; font-size:16px\"><strong>\n",
    "Boolean features: </strong></span>\n",
    "- internet_access: 2 values [yes, no]-> 90/10 split with **very weak** predictive power\n",
    "\n",
    "<span style= \"color:DarkSeaGreen; font-size:16px\"><strong>\n",
    "Categorical (non-ordinal) features: </strong></span>\n",
    "- gender: 3 values [female, male, other]-> uniform distribution with **no** significant independent predictive power \n",
    "- course: 7 values [b.sc, diploma, bca, b.com, ba, bba, b.tech] -> **weak** predictive power \n",
    "- study_method: 5 values [online videos, self-study, coaching, group study, mixed] -> uniform distribution with **weak** predictive power\n",
    "\n",
    "<span style= \"color:DarkSeaGreen; font-size:16px\"><strong>\n",
    "Categorical (ordinal) features: </strong></span>\n",
    "- sleep_quality: 3 values [poor, average, good] -> uniform distribution with **strong** predictive power \n",
    "- facility_rating: 3 values [low, medium, high] -> uniform distribuion with **strong** predictive power\n",
    "- exam_difficulty: 3 values [easy, moderate, hard] -> symetric distribution with **very weak** predictive power\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
